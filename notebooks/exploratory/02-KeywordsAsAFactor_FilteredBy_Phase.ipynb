{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keywords as a Factor\n",
    "\n",
    "### (Started Jun 30, 2019)\n",
    "\n",
    "Continuing from Notebook 01-FirstDataExploration I will begin analyzing the article titles for keywords that could have some interesting statistical properties.\n",
    "\n",
    "## Information from the Previous Notebook\n",
    "\n",
    "Now, it would be good to look through the keywords from the article titles and see if there are any keywords that are indicitive of positive or negative results.\n",
    "\n",
    "The initial look will be very basic and intuitive as we are just take a first look.\n",
    "\n",
    "Hypothesis:\n",
    "* Words like positive and negative should be telling of which direction the stock will go. Also w.r.t. exploration there should be other words that may be helpful in determining the direction (and possibly the magnitude)\n",
    "\n",
    "Collect all of the \"important\" words (using NLP practices) for a bag of words.\n",
    "\n",
    "Seperate the events into classes, in this case will use quartiles (this can be changed later on). For each word that has \"enough\" frequency we want to get as much information as possible about the probability of a company ending in each quartile bracket.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [\"Import and Settings\"](#1)\n",
    "2. [\"Importing and Cleaning Data\"](#2)\n",
    "3. [\"NLP Exploration\"](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Settings\n",
    "<a id=\"1\"><a/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Numerical Libraries\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Visual Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Local Package Libraries\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from src.data.make_dataset import clean_and_open_business_wire_data_01, get_raw_data\n",
    "from src.features.general_helper_functions import GetPrices\n",
    "from src.features.nlp_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Settings\n",
    "\n",
    "# Stop the warnings for chain in pandas...\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important;}</style>\"))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Cleaning the Data\n",
    "<a id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, watchlist_raw, stock_prices_raw = get_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_trial_df = clean_and_open_business_wire_data_01(None)\n",
    "clinical_trial_df.time = pd.to_datetime(clinical_trial_df.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size:  (721, 4)\n",
      "Final size:  (197, 4)\n",
      "Original size:  (5402, 208)\n",
      "Final size:  (5402, 197)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACAD</th>\n",
       "      <th>ACHC</th>\n",
       "      <th>ACOR</th>\n",
       "      <th>ADUS</th>\n",
       "      <th>AERI</th>\n",
       "      <th>AGIO</th>\n",
       "      <th>AIMT</th>\n",
       "      <th>AKCA</th>\n",
       "      <th>AKRX</th>\n",
       "      <th>ALDR</th>\n",
       "      <th>...</th>\n",
       "      <th>VRAY</th>\n",
       "      <th>VREX</th>\n",
       "      <th>WMGI</th>\n",
       "      <th>WVE</th>\n",
       "      <th>XENT</th>\n",
       "      <th>XLRN</th>\n",
       "      <th>XNCR</th>\n",
       "      <th>XON</th>\n",
       "      <th>YI</th>\n",
       "      <th>ZGNX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-06-17</th>\n",
       "      <td>25.42</td>\n",
       "      <td>34.00</td>\n",
       "      <td>7.68</td>\n",
       "      <td>72.56</td>\n",
       "      <td>33.29</td>\n",
       "      <td>50.66</td>\n",
       "      <td>20.54</td>\n",
       "      <td>24.39</td>\n",
       "      <td>4.34</td>\n",
       "      <td>12.45</td>\n",
       "      <td>...</td>\n",
       "      <td>8.95</td>\n",
       "      <td>28.21</td>\n",
       "      <td>31.31</td>\n",
       "      <td>27.43</td>\n",
       "      <td>24.45</td>\n",
       "      <td>38.36</td>\n",
       "      <td>32.55</td>\n",
       "      <td>7.60</td>\n",
       "      <td>6.75</td>\n",
       "      <td>40.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-18</th>\n",
       "      <td>25.93</td>\n",
       "      <td>34.20</td>\n",
       "      <td>7.66</td>\n",
       "      <td>72.92</td>\n",
       "      <td>33.84</td>\n",
       "      <td>51.91</td>\n",
       "      <td>20.20</td>\n",
       "      <td>23.98</td>\n",
       "      <td>4.48</td>\n",
       "      <td>11.73</td>\n",
       "      <td>...</td>\n",
       "      <td>9.13</td>\n",
       "      <td>28.95</td>\n",
       "      <td>31.69</td>\n",
       "      <td>27.92</td>\n",
       "      <td>23.97</td>\n",
       "      <td>40.62</td>\n",
       "      <td>34.54</td>\n",
       "      <td>8.60</td>\n",
       "      <td>6.62</td>\n",
       "      <td>39.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-19</th>\n",
       "      <td>26.62</td>\n",
       "      <td>34.04</td>\n",
       "      <td>7.54</td>\n",
       "      <td>75.89</td>\n",
       "      <td>32.89</td>\n",
       "      <td>51.42</td>\n",
       "      <td>20.07</td>\n",
       "      <td>22.80</td>\n",
       "      <td>4.65</td>\n",
       "      <td>11.55</td>\n",
       "      <td>...</td>\n",
       "      <td>9.11</td>\n",
       "      <td>29.26</td>\n",
       "      <td>31.88</td>\n",
       "      <td>26.93</td>\n",
       "      <td>24.16</td>\n",
       "      <td>39.92</td>\n",
       "      <td>34.65</td>\n",
       "      <td>8.55</td>\n",
       "      <td>6.62</td>\n",
       "      <td>40.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-20</th>\n",
       "      <td>25.73</td>\n",
       "      <td>34.52</td>\n",
       "      <td>7.28</td>\n",
       "      <td>74.91</td>\n",
       "      <td>32.13</td>\n",
       "      <td>51.30</td>\n",
       "      <td>20.24</td>\n",
       "      <td>22.90</td>\n",
       "      <td>4.74</td>\n",
       "      <td>11.54</td>\n",
       "      <td>...</td>\n",
       "      <td>8.92</td>\n",
       "      <td>29.57</td>\n",
       "      <td>30.48</td>\n",
       "      <td>26.86</td>\n",
       "      <td>23.62</td>\n",
       "      <td>40.85</td>\n",
       "      <td>35.10</td>\n",
       "      <td>8.01</td>\n",
       "      <td>6.62</td>\n",
       "      <td>40.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-21</th>\n",
       "      <td>26.00</td>\n",
       "      <td>34.72</td>\n",
       "      <td>7.49</td>\n",
       "      <td>74.63</td>\n",
       "      <td>30.91</td>\n",
       "      <td>50.78</td>\n",
       "      <td>20.00</td>\n",
       "      <td>24.26</td>\n",
       "      <td>4.78</td>\n",
       "      <td>11.60</td>\n",
       "      <td>...</td>\n",
       "      <td>8.72</td>\n",
       "      <td>29.21</td>\n",
       "      <td>30.09</td>\n",
       "      <td>26.18</td>\n",
       "      <td>23.15</td>\n",
       "      <td>40.18</td>\n",
       "      <td>35.16</td>\n",
       "      <td>7.57</td>\n",
       "      <td>6.49</td>\n",
       "      <td>40.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ACAD   ACHC  ACOR   ADUS   AERI   AGIO   AIMT   AKCA  AKRX  \\\n",
       "2019-06-17  25.42  34.00  7.68  72.56  33.29  50.66  20.54  24.39  4.34   \n",
       "2019-06-18  25.93  34.20  7.66  72.92  33.84  51.91  20.20  23.98  4.48   \n",
       "2019-06-19  26.62  34.04  7.54  75.89  32.89  51.42  20.07  22.80  4.65   \n",
       "2019-06-20  25.73  34.52  7.28  74.91  32.13  51.30  20.24  22.90  4.74   \n",
       "2019-06-21  26.00  34.72  7.49  74.63  30.91  50.78  20.00  24.26  4.78   \n",
       "\n",
       "             ALDR  ...    VRAY   VREX   WMGI    WVE   XENT   XLRN   XNCR  \\\n",
       "2019-06-17  12.45  ...    8.95  28.21  31.31  27.43  24.45  38.36  32.55   \n",
       "2019-06-18  11.73  ...    9.13  28.95  31.69  27.92  23.97  40.62  34.54   \n",
       "2019-06-19  11.55  ...    9.11  29.26  31.88  26.93  24.16  39.92  34.65   \n",
       "2019-06-20  11.54  ...    8.92  29.57  30.48  26.86  23.62  40.85  35.10   \n",
       "2019-06-21  11.60  ...    8.72  29.21  30.09  26.18  23.15  40.18  35.16   \n",
       "\n",
       "             XON    YI   ZGNX  \n",
       "2019-06-17  7.60  6.75  40.30  \n",
       "2019-06-18  8.60  6.62  39.79  \n",
       "2019-06-19  8.55  6.62  40.37  \n",
       "2019-06-20  8.01  6.62  40.91  \n",
       "2019-06-21  7.57  6.49  40.62  \n",
       "\n",
       "[5 rows x 197 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Watchlist\n",
    "\n",
    "# 0: Create a copy of the data\n",
    "watchlist_df = watchlist_raw.copy()\n",
    "print(\"Original size: \", watchlist_df.shape)\n",
    "\n",
    "# 1: Get a list of the unique companies that have scraped article data\n",
    "unique_companies = clinical_trial_df.ticker.unique()\n",
    "\n",
    "# 2: Keep only the companies from the list\n",
    "watchlist_df = watchlist_df.loc[watchlist_df.Ticker.isin(unique_companies)]\n",
    "print(\"Final size: \", watchlist_df.shape)\n",
    "\n",
    "watchlist_df.columns = [\"ticker\", \"marketcap\", \"sector\", \"exchange\"]\n",
    "\n",
    "watchlist_df.head()\n",
    "\n",
    "\n",
    "# Stock Prices\n",
    "\n",
    "# 0: Make a copy of the stock prices here\n",
    "prices_df = stock_prices_raw.copy()\n",
    "print(\"Original size: \", prices_df.shape)\n",
    "\n",
    "# 1: Reduce the new copy of prices to only the companies under our scope\n",
    "prices_df = prices_df[unique_companies]\n",
    "print(\"Final size: \", prices_df.shape)\n",
    "\n",
    "# 2: Sort by date\n",
    "prices_df.sort_index(inplace=True)\n",
    "\n",
    "# 3: Ensure index is datetime object\n",
    "prices_df.index = pd.to_datetime(prices_df.index)\n",
    "\n",
    "prices_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for \"Phase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered size:  (226, 4)\n"
     ]
    }
   ],
   "source": [
    "df_filtered_for_phase = clinical_trial_df.loc[clinical_trial_df.title.str.contains(\"phase\")]\n",
    "print(\"Filtered size: \", df_filtered_for_phase.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the Stock Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      P_0    P_1    P_2    P_3    P_4\n",
      "1     NaN    NaN    NaN    NaN    NaN\n",
      "6   24.45  25.17  25.12  24.05  23.66\n",
      "12  26.24  26.64  26.85  26.98  27.32\n",
      "25  19.48  22.36  22.73  21.66  21.88\n",
      "22  16.89  16.26  15.93  16.01  15.56\n",
      "         R_0       R_1       R_2       R_3\n",
      "1        NaN       NaN       NaN       NaN\n",
      "6   0.029448  0.027403 -0.016360 -0.032311\n",
      "12  0.015244  0.023247  0.028201  0.041159\n",
      "25  0.147844  0.166838  0.111910  0.123203\n",
      "22 -0.037300 -0.056838 -0.052102 -0.078745\n"
     ]
    }
   ],
   "source": [
    "# Get the stock prices for 30 days following each event\n",
    "price_window = GetPrices(\n",
    "    df_filtered_for_phase, \n",
    "    prices_df, \n",
    "    n_window=5\n",
    ").add_prices_to_frame()\n",
    "\n",
    "#.dropna(axis=0, inplace=True)\n",
    "print(price_window.head())\n",
    "\n",
    "def perc_return(value_matrix, i, j):\n",
    "    return (value_matrix[j][i] / value_matrix[j][0]) - 1\n",
    "\n",
    "\n",
    "return_values = np.array([\n",
    "    np.array([\n",
    "        perc_return(price_window.values, i, j) for i in range(1, price_window.values.shape[1])\n",
    "    ]) for j in range(price_window.values.shape[0])\n",
    "])\n",
    "\n",
    "\n",
    "cols = [\"R_{}\".format(i) for i in range(return_values.shape[1])]\n",
    "\n",
    "return_window = pd.DataFrame(return_values, index=price_window.index, columns=cols)\n",
    "\n",
    "print(return_window.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# July 1, 2019 - Create a function that encapsulates the above code block\n",
    "def compute_return_window(article_df, prices_df, n_window=30):\n",
    "    \n",
    "    # Get the stock prices for \"n\" days following each event\n",
    "    price_window = GetPrices(\n",
    "        article_df, \n",
    "        prices_df, \n",
    "        n_window=n_window\n",
    "    ).add_prices_to_frame()\n",
    "\n",
    "\n",
    "    return_values = np.array([\n",
    "        np.array([\n",
    "            perc_return(price_window.values, i, j) for i in range(1, price_window.values.shape[1])\n",
    "        ]) for j in range(price_window.values.shape[0])\n",
    "    ])\n",
    "\n",
    "\n",
    "    cols = [\"R_{}\".format(i) for i in range(return_values.shape[1])]\n",
    "\n",
    "    return pd.DataFrame(return_values, index=price_window.index, columns=cols)\n",
    "\n",
    "return_window = compute_return_window(df_filtered_for_phase, prices_df, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Feature Exploration\n",
    "<a id=\"3\"></a>\n",
    "\n",
    "In this section we will clean up the title in df_filtered_for_phase data using:\n",
    "\n",
    "* remove_white_spaces\n",
    "* remove_non_alphanumeric\n",
    "* remove_numbers\n",
    "* remove_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# July 1, 2019\n",
    "def clean_text(df, column_name):\n",
    "    df[column_name] = df[column_name].apply(remove_white_spaces)\n",
    "    df[column_name] = df[column_name].apply(remove_non_alphanumeric)\n",
    "    df[column_name] = df[column_name].apply(remove_numbers)\n",
    "    df[column_name] = df[column_name].apply(remove_stop_words)\n",
    "    df[column_name] = df[column_name].apply(remove_stop_words)\n",
    "    df[column_name] = df[column_name].apply(lemmatize_text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>ticker</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-18</td>\n",
       "      <td>present phase  clarity result pimavanserin adj...</td>\n",
       "      <td>ACAD</td>\n",
       "      <td>san diego--(business wire)--acadia pharmaceut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-04-25</td>\n",
       "      <td>initiate phase  clarity program pimavanserin a...</td>\n",
       "      <td>ACAD</td>\n",
       "      <td>san diego--(business wire)--acadia pharmaceut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-03-27</td>\n",
       "      <td>positive phase  study result trofinetide pedia...</td>\n",
       "      <td>ACAD</td>\n",
       "      <td>san diego &amp; cincinnati &amp; melbourne, australia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>announce positive top line result phase  clari...</td>\n",
       "      <td>ACAD</td>\n",
       "      <td>san diego--(business wire)--acadia pharmaceut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019-01-17</td>\n",
       "      <td>announce lancet neurology publication phase  d...</td>\n",
       "      <td>ACOR</td>\n",
       "      <td>ardsley, n.y.--(business wire)--acorda therap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time                                              title ticker  \\\n",
       "1  2019-05-18  present phase  clarity result pimavanserin adj...   ACAD   \n",
       "6  2019-04-25  initiate phase  clarity program pimavanserin a...   ACAD   \n",
       "12 2019-03-27  positive phase  study result trofinetide pedia...   ACAD   \n",
       "25 2018-10-31  announce positive top line result phase  clari...   ACAD   \n",
       "22 2019-01-17  announce lancet neurology publication phase  d...   ACOR   \n",
       "\n",
       "                                              article  \n",
       "1    san diego--(business wire)--acadia pharmaceut...  \n",
       "6    san diego--(business wire)--acadia pharmaceut...  \n",
       "12   san diego & cincinnati & melbourne, australia...  \n",
       "25   san diego--(business wire)--acadia pharmaceut...  \n",
       "22   ardsley, n.y.--(business wire)--acorda therap...  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = clean_text(df_filtered_for_phase, \"title\")\n",
    "\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the titles again I noticed that the company's name is also generally in the title. It would be best to remove that as the company will already be it's own feature implicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_names = watchlist_df.loc[watchlist_df.ticker.isin(unique_companies)].index.tolist()\n",
    "articles.title = articles.title.apply(remove_company_name, args=(company_names,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now need our set of unique keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_titles = \" \".join(articles.title.values.tolist())\n",
    "\n",
    "set_of_words = list(set(combined_titles.split(\" \")))\n",
    "set_of_words.remove(\"\")\n",
    "\n",
    "len(set_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also want to remove all \"words\" that have 2 or less characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_of_words.remove(\"phase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "827"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_of_words = [word for word in set_of_words if len(word) > 2]\n",
    "\n",
    "len(set_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need a function that, given a data frame (or sub data frame) with the article titles, will give the frequency that the word occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_frequency(word_list, df):\n",
    "    d = {word: sum([1 if word in article else 0 for article in df.title.values])/df.shape[0] for word in word_list}\n",
    "    \n",
    "    return pd.Series(d, index = d.keys()).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trial        0.469027\n",
       "clinical     0.314159\n",
       "announce     0.309735\n",
       "patient      0.305310\n",
       "study        0.292035\n",
       "results      0.269912\n",
       "announces    0.256637\n",
       "com          0.252212\n",
       "patients     0.247788\n",
       "pre          0.238938\n",
       "ted          0.207965\n",
       "line         0.199115\n",
       "data         0.176991\n",
       "treatment    0.172566\n",
       "present      0.163717\n",
       "positive     0.154867\n",
       "met          0.150442\n",
       "initiate     0.132743\n",
       "cancer       0.123894\n",
       "anal         0.119469\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency = calculate_word_frequency(set_of_words, articles)\n",
    "word_frequency.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what we are looking for are words that are in a *substantial* number of documents and provide *enough* classification information.\n",
    "\n",
    "by substantial, in this case I will use an absolute cut-off of 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trial', 'clinical', 'announce', 'patient', 'study', 'results',\n",
       "       'announces', 'com', 'patients', 'pre', 'ted', 'line', 'data',\n",
       "       'treatment', 'present', 'positive', 'met', 'initiate', 'cancer', 'anal',\n",
       "       'market', 'research', 'initiates', 'markets', 'first', 'report',\n",
       "       'analysis', 'med', 'chi', 'pipeline', 'iii', 'cell', 'advanced',\n",
       "       'annual', 'car', 'top', 'enroll', 'disease', 'end', 'meeting',\n",
       "       'researchandmarkets', 'age', 'update', 'develop', 'society',\n",
       "       'development', 'tumor', 'anti', 'presents', 'complete', 'reports',\n",
       "       'enrollment', 'point', 'part', 'pivotal', 'carcinoma', 'iga', 'europe',\n",
       "       'tumors'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_of_words = word_frequency.loc[word_frequency > 0.05].index\n",
    "set_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive and Negative Frequency Ratio\n",
    "\n",
    "These numbers will give the frequency of each word in the positive return or negative return events divided by the total number of the positive or negative return events respectively.\n",
    "\n",
    "I will build the function to take in the return number so I can build this part out to test on various days for optimality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_return_window(ret_df, holding_period=0):\n",
    "    '''returns the positive and negative dataframes, in that order.'''\n",
    "    pos = ret_df.loc[ret_df[\"R_{}\".format(holding_period)] > 0].index\n",
    "    neg = ret_df.loc[ret_df[\"R_{}\".format(holding_period)] <= 0].index\n",
    "    \n",
    "    return pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ind, neg_ind = split_return_window(return_window, 0)\n",
    "\n",
    "pos_articles = articles.loc[pos_ind]\n",
    "neg_articles = articles.loc[neg_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_word_freq = calculate_word_frequency(set_of_words, pos_articles)\n",
    "neg_word_freq = calculate_word_frequency(set_of_words, neg_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trial</th>\n",
       "      <td>0.468198</td>\n",
       "      <td>0.448622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient</th>\n",
       "      <td>0.326855</td>\n",
       "      <td>0.325815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announce</th>\n",
       "      <td>0.325088</td>\n",
       "      <td>0.300752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study</th>\n",
       "      <td>0.298587</td>\n",
       "      <td>0.273183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clinical</th>\n",
       "      <td>0.291519</td>\n",
       "      <td>0.290727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announces</th>\n",
       "      <td>0.273852</td>\n",
       "      <td>0.260652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patients</th>\n",
       "      <td>0.266784</td>\n",
       "      <td>0.253133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com</th>\n",
       "      <td>0.257951</td>\n",
       "      <td>0.303258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>results</th>\n",
       "      <td>0.234982</td>\n",
       "      <td>0.243108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>0.226148</td>\n",
       "      <td>0.223058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pos       neg\n",
       "trial      0.468198  0.448622\n",
       "patient    0.326855  0.325815\n",
       "announce   0.325088  0.300752\n",
       "study      0.298587  0.273183\n",
       "clinical   0.291519  0.290727\n",
       "announces  0.273852  0.260652\n",
       "patients   0.266784  0.253133\n",
       "com        0.257951  0.303258\n",
       "results    0.234982  0.243108\n",
       "line       0.226148  0.223058"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_df = pd.DataFrame([pos_word_freq, neg_word_freq], index = [\"pos\", \"neg\"]).T\n",
    "sent_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the difference between the columns. This would indicate a \"lean\" towards on direction or another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df[\"diff\"] = sent_df.pos - sent_df.neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sent_df.sort_values(\"diff\", inplace=True, ascending=False)\n",
    "\n",
    "top_10 = sent_df.iloc[:10]\n",
    "bottom_10 = sent_df.iloc[:-10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>top</th>\n",
       "      <th>initiate</th>\n",
       "      <th>initiates</th>\n",
       "      <th>first</th>\n",
       "      <th>study</th>\n",
       "      <th>announce</th>\n",
       "      <th>tumors</th>\n",
       "      <th>treatment</th>\n",
       "      <th>pivotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>0.160777</td>\n",
       "      <td>0.093640</td>\n",
       "      <td>0.143110</td>\n",
       "      <td>0.123675</td>\n",
       "      <td>0.125442</td>\n",
       "      <td>0.298587</td>\n",
       "      <td>0.325088</td>\n",
       "      <td>0.077739</td>\n",
       "      <td>0.171378</td>\n",
       "      <td>0.070671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.062657</td>\n",
       "      <td>0.112782</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.097744</td>\n",
       "      <td>0.273183</td>\n",
       "      <td>0.300752</td>\n",
       "      <td>0.055138</td>\n",
       "      <td>0.150376</td>\n",
       "      <td>0.050125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>0.037970</td>\n",
       "      <td>0.030983</td>\n",
       "      <td>0.030328</td>\n",
       "      <td>0.028437</td>\n",
       "      <td>0.027697</td>\n",
       "      <td>0.025404</td>\n",
       "      <td>0.024336</td>\n",
       "      <td>0.022601</td>\n",
       "      <td>0.021002</td>\n",
       "      <td>0.020546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      positive       top  initiate  initiates     first     study  announce  \\\n",
       "pos   0.160777  0.093640  0.143110   0.123675  0.125442  0.298587  0.325088   \n",
       "neg   0.122807  0.062657  0.112782   0.095238  0.097744  0.273183  0.300752   \n",
       "diff  0.037970  0.030983  0.030328   0.028437  0.027697  0.025404  0.024336   \n",
       "\n",
       "        tumors  treatment   pivotal  \n",
       "pos   0.077739   0.171378  0.070671  \n",
       "neg   0.055138   0.150376  0.050125  \n",
       "diff  0.022601   0.021002  0.020546  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>present</th>\n",
       "      <th>pre</th>\n",
       "      <th>com</th>\n",
       "      <th>annual</th>\n",
       "      <th>data</th>\n",
       "      <th>end</th>\n",
       "      <th>ted</th>\n",
       "      <th>pipeline</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>0.120141</td>\n",
       "      <td>0.197880</td>\n",
       "      <td>0.257951</td>\n",
       "      <td>0.049470</td>\n",
       "      <td>0.151943</td>\n",
       "      <td>0.058304</td>\n",
       "      <td>0.183746</td>\n",
       "      <td>0.097173</td>\n",
       "      <td>0.060071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>0.182957</td>\n",
       "      <td>0.255639</td>\n",
       "      <td>0.303258</td>\n",
       "      <td>0.090226</td>\n",
       "      <td>0.187970</td>\n",
       "      <td>0.092732</td>\n",
       "      <td>0.218045</td>\n",
       "      <td>0.127820</td>\n",
       "      <td>0.090226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>-0.062816</td>\n",
       "      <td>-0.057759</td>\n",
       "      <td>-0.045308</td>\n",
       "      <td>-0.040756</td>\n",
       "      <td>-0.036026</td>\n",
       "      <td>-0.034428</td>\n",
       "      <td>-0.034300</td>\n",
       "      <td>-0.030646</td>\n",
       "      <td>-0.030155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       present       pre       com    annual      data       end       ted  \\\n",
       "pos   0.120141  0.197880  0.257951  0.049470  0.151943  0.058304  0.183746   \n",
       "neg   0.182957  0.255639  0.303258  0.090226  0.187970  0.092732  0.218045   \n",
       "diff -0.062816 -0.057759 -0.045308 -0.040756 -0.036026 -0.034428 -0.034300   \n",
       "\n",
       "      pipeline   disease  \n",
       "pos   0.097173  0.060071  \n",
       "neg   0.127820  0.090226  \n",
       "diff -0.030646 -0.030155  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_10.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright so, now we have a way to get the top and bottom scoring words.\n",
    "\n",
    "Now would like to convert this notebook portion into a piece of production code. This will allow further investigation on what keywords are important as I can look to longer holding periods.\n",
    "\n",
    "Remember, for now, I am simply looking for keywords as factors. They will likely be pushed in as contains_word = {True, False} later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_frequency(word_list, df):\n",
    "    d = {word: sum([1 if word in article else 0 for article in df.title.values])/df.shape[0] for word in word_list}\n",
    "    \n",
    "    return pd.Series(d, index = d.keys()).sort_values(ascending=False)\n",
    "\n",
    "def split_return_window(ret_df, holding_period=0):\n",
    "    '''returns the positive and negative dataframes, in that order.'''\n",
    "    pos = ret_df.loc[ret_df[\"R_{}\".format(holding_period)] > 0].index\n",
    "    neg = ret_df.loc[ret_df[\"R_{}\".format(holding_period)] <= 0].index\n",
    "    \n",
    "    return pos, neg\n",
    "\n",
    "def calculate_top_and_bottom_keywords(article_df, return_df, holding_period, cut_off=0.05):\n",
    "    combined_titles = \" \".join(articles.title.values.tolist())\n",
    "\n",
    "    set_of_words = list(set(combined_titles.split(\" \")))\n",
    "    set_of_words.remove(\"\")\n",
    "    set_of_words.remove(\"phase\")\n",
    "    \n",
    "    set_of_words = [word for word in set_of_words if len(word) > 2]\n",
    "\n",
    "    word_frequency = calculate_word_frequency(set_of_words, articles)\n",
    "    \n",
    "    set_of_words = word_frequency.loc[word_frequency > cut_off].index\n",
    "    \n",
    "    pos_ind, neg_ind = split_return_window(return_df, holding_period)\n",
    "\n",
    "    pos_articles = articles.loc[pos_ind]\n",
    "    neg_articles = articles.loc[neg_ind]\n",
    "    \n",
    "    pos_word_freq = calculate_word_frequency(set_of_words, pos_articles)\n",
    "    neg_word_freq = calculate_word_frequency(set_of_words, neg_articles)\n",
    "    \n",
    "    sent_df = pd.DataFrame([pos_word_freq, neg_word_freq], index = [\"pos\", \"neg\"]).T\n",
    "    \n",
    "    sent_df[\"diff\"] = sent_df.pos - sent_df.neg\n",
    "    \n",
    "    sent_df.sort_values(\"diff\", inplace=True, ascending=False)\n",
    "\n",
    "    return sent_df[\"diff\"].iloc[:10], sent_df[\"diff\"].iloc[:-10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(positive     0.037970\n",
       " top          0.030983\n",
       " initiate     0.030328\n",
       " initiates    0.028437\n",
       " first        0.027697\n",
       " study        0.025404\n",
       " announce     0.024336\n",
       " tumors       0.022601\n",
       " treatment    0.021002\n",
       " pivotal      0.020546\n",
       " Name: diff, dtype: float64, present    -0.062816\n",
       " pre        -0.057759\n",
       " com        -0.045308\n",
       " annual     -0.040756\n",
       " data       -0.036026\n",
       " end        -0.034428\n",
       " ted        -0.034300\n",
       " pipeline   -0.030646\n",
       " disease    -0.030155\n",
       " Name: diff, dtype: float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_top_and_bottom_keywords(articles.title, return_window, 0, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! It works, will add to src and refactor there.\n",
    "\n",
    "Further, we can create a dataframe that tracks which words are import through time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thought Update\n",
    "\n",
    "I would like to revise the work a little bit above. Since we are working with returns, it doesn't make much sense to use binary classification. What would be better is instead to use return metrics that are common in industry such as Sharpe Ratio, and classify the top words for that.\n",
    "\n",
    "It would also be interested to look at the following:\n",
    "1. Using Feature Importance from a Tree model\n",
    "2. Using these concepts on the overall data to see if there are keywords that could be important for all articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## July 1, 2019\n",
    "\n",
    "From here, I would like to start using industry metrics. There are several to choose from, so it would be great to implement a function that could take in the metric seperately. This will be done later, for now I will simply use something similar to a Sharpe Ratio.\n",
    "\n",
    "$$ S = \\frac{r_{portfolio} - r_{free}}{\\sigma} $$\n",
    "\n",
    "In this instance, we will assume the risk free return is zero and can be implemented later if need be.\n",
    "\n",
    "To find the top and bottom *N* stocks, simply get order the words that had the best sharpe ratio.\n",
    "\n",
    "**Steps**\n",
    "1. Filter the set of words as before\n",
    "2. For each word:\n",
    "    * get the list of all event_ids of the articles containing a word\n",
    "    * get the holding period's returns\n",
    "    * calculated the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "develop        1.338537\n",
      "development    1.248778\n",
      "pivotal        0.735344\n",
      "positive       0.606156\n",
      "meet           0.555026\n",
      "europe         0.459805\n",
      "annual         0.442164\n",
      "point          0.423565\n",
      "first          0.408091\n",
      "data           0.380608\n",
      "dtype: float64\n",
      "\n",
      "study                -0.056246\n",
      "cancer               -0.067508\n",
      "enroll               -0.098866\n",
      "enrol                -0.098866\n",
      "market               -0.107381\n",
      "research             -0.112427\n",
      "initiate             -0.177212\n",
      "dose                 -0.247407\n",
      "tumor                -0.335094\n",
      "researchandmarkets   -0.338697\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def calculate_word_frequency(word_list, df):\n",
    "    d = {word: sum([1 if word in article else 0 for article in df.title.values])/df.shape[0] for word in word_list}\n",
    "    \n",
    "    return pd.Series(d, index = d.keys()).sort_values(ascending=False)\n",
    "\n",
    "\n",
    "def clean_word_list(articles, cut_off):\n",
    "    combined_titles = \" \".join(articles.title.values.tolist())\n",
    "\n",
    "    set_of_words = list(set(combined_titles.split(\" \")))\n",
    "    \n",
    "    set_of_words = [word for word in set_of_words if len(word) > 3]\n",
    "\n",
    "    word_frequency = calculate_word_frequency(set_of_words, articles)\n",
    "    set_of_words = word_frequency.loc[word_frequency > cut_off].index\n",
    "    return set_of_words\n",
    "\n",
    "def naive_sharpe(series):\n",
    "    expected_return = series.mean()\n",
    "    dev = series.std()\n",
    "    return expected_return / dev\n",
    "\n",
    "def calculate_sharpe_ratio(article_df, return_df, holding_period, cut_off=0.05):\n",
    "    set_of_words = clean_word_list(article_df, cut_off)\n",
    "    \n",
    "    # In case the user inserts a holding period longer than allowed\n",
    "    holding_period = min([len(return_df.columns) - 1, holding_period])\n",
    "    \n",
    "    sharpe_dict = {}\n",
    "    for word in set_of_words:\n",
    "        event_id_list = article_df.loc[article_df.title.str.contains(word)].index.tolist()\n",
    "        returns = return_df[\"R_{}\".format(holding_period)].iloc[event_id_list]\n",
    "        sharpe_dict[word] = naive_sharpe(returns)\n",
    "        \n",
    "    S = pd.Series(sharpe_dict, index=sharpe_dict.keys())\n",
    "    S.sort_values(ascending=False, inplace=True)\n",
    "    return S\n",
    "\n",
    "res = calculate_sharpe_ratio(articles, return_window, 0, 0.05)\n",
    "\n",
    "print(res.head(10))\n",
    "print(\"\")\n",
    "print(res.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Test\n",
    "\n",
    "Let's try the functionality on the entire article data frame instead of the filtered one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cutoff 8155\n",
      "After cutoff 280 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "clinical_trial_df = clean_text(clinical_trial_df, \"title\")\n",
    "all_article_return_window = compute_return_window(clinical_trial_df, \n",
    "                                                  prices_df, \n",
    "                                                  n_window=30)\n",
    "\n",
    "res_full = calculate_top_and_bottom_sharpe(clinical_trial_df, all_article_return_window, 30, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file          0.100213\n",
       "drug          0.099866\n",
       "conference    0.099143\n",
       "review        0.097758\n",
       "view          0.097072\n",
       "announces     0.096882\n",
       "lion          0.096798\n",
       "finan         0.096383\n",
       "announce      0.096245\n",
       "report        0.096028\n",
       "dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S[0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "markets               0.089124\n",
       "research              0.089087\n",
       "search                0.089086\n",
       "ology                 0.088967\n",
       "care                  0.088208\n",
       "rate                  0.087484\n",
       "point                 0.084747\n",
       "chan                  0.075342\n",
       "hand                  0.074920\n",
       "researchandmarkets    0.074810\n",
       "dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S[0].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Functionality\n",
    "\n",
    "After thinking about the project I realized I would like to make a few changes. The reason is to get more flexbility with metrics. The output of the function will have the following columns:\n",
    "* Expected Return\n",
    "* Standard Deviation of Returns\n",
    "* Skew of Returns\n",
    "* Kurtosis of Returns\n",
    "* Number of instances (Trades)\n",
    "\n",
    "Then after that, it will be easier to look at various metrics using a seperate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>return</th>\n",
       "      <th>dev</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>freq_occurance</th>\n",
       "      <th>sharpe_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>0.073607</td>\n",
       "      <td>0.147450</td>\n",
       "      <td>0.456285</td>\n",
       "      <td>-1.116461</td>\n",
       "      <td>0.075221</td>\n",
       "      <td>1.414034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.051755</td>\n",
       "      <td>0.134496</td>\n",
       "      <td>0.373000</td>\n",
       "      <td>-0.289800</td>\n",
       "      <td>0.115044</td>\n",
       "      <td>1.071286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>0.059078</td>\n",
       "      <td>0.178998</td>\n",
       "      <td>2.363357</td>\n",
       "      <td>8.521557</td>\n",
       "      <td>0.207965</td>\n",
       "      <td>0.925543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>0.052210</td>\n",
       "      <td>0.163599</td>\n",
       "      <td>0.225875</td>\n",
       "      <td>-0.954824</td>\n",
       "      <td>0.115044</td>\n",
       "      <td>0.888904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announce</th>\n",
       "      <td>0.047411</td>\n",
       "      <td>0.156897</td>\n",
       "      <td>0.333173</td>\n",
       "      <td>-0.739548</td>\n",
       "      <td>0.203540</td>\n",
       "      <td>0.836712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study</th>\n",
       "      <td>0.066944</td>\n",
       "      <td>0.227307</td>\n",
       "      <td>2.116217</td>\n",
       "      <td>5.379617</td>\n",
       "      <td>0.207965</td>\n",
       "      <td>0.830850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treat</th>\n",
       "      <td>0.049928</td>\n",
       "      <td>0.208747</td>\n",
       "      <td>2.251961</td>\n",
       "      <td>6.192323</td>\n",
       "      <td>0.146018</td>\n",
       "      <td>0.664431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clinical</th>\n",
       "      <td>0.051560</td>\n",
       "      <td>0.220976</td>\n",
       "      <td>2.059625</td>\n",
       "      <td>5.814816</td>\n",
       "      <td>0.238938</td>\n",
       "      <td>0.649435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>0.022746</td>\n",
       "      <td>0.120187</td>\n",
       "      <td>0.336363</td>\n",
       "      <td>-0.190480</td>\n",
       "      <td>0.115044</td>\n",
       "      <td>0.487325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treatment</th>\n",
       "      <td>0.020971</td>\n",
       "      <td>0.139303</td>\n",
       "      <td>0.965044</td>\n",
       "      <td>-0.214014</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.382884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phase</th>\n",
       "      <td>0.024299</td>\n",
       "      <td>0.173815</td>\n",
       "      <td>1.880707</td>\n",
       "      <td>6.853316</td>\n",
       "      <td>0.685841</td>\n",
       "      <td>0.363305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <td>0.019955</td>\n",
       "      <td>0.143418</td>\n",
       "      <td>0.466266</td>\n",
       "      <td>-0.204099</td>\n",
       "      <td>0.097345</td>\n",
       "      <td>0.351025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancer</th>\n",
       "      <td>0.013988</td>\n",
       "      <td>0.120818</td>\n",
       "      <td>0.200386</td>\n",
       "      <td>0.171816</td>\n",
       "      <td>0.097345</td>\n",
       "      <td>0.271105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient</th>\n",
       "      <td>0.015926</td>\n",
       "      <td>0.190402</td>\n",
       "      <td>2.468305</td>\n",
       "      <td>8.815539</td>\n",
       "      <td>0.194690</td>\n",
       "      <td>0.202019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial</th>\n",
       "      <td>0.004705</td>\n",
       "      <td>0.137817</td>\n",
       "      <td>0.570613</td>\n",
       "      <td>0.136804</td>\n",
       "      <td>0.349558</td>\n",
       "      <td>0.039105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>report</th>\n",
       "      <td>0.005654</td>\n",
       "      <td>0.228321</td>\n",
       "      <td>3.358050</td>\n",
       "      <td>10.662194</td>\n",
       "      <td>0.079646</td>\n",
       "      <td>0.035851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>present</th>\n",
       "      <td>-0.002179</td>\n",
       "      <td>0.134554</td>\n",
       "      <td>0.514281</td>\n",
       "      <td>0.299960</td>\n",
       "      <td>0.128319</td>\n",
       "      <td>-0.110766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meet</th>\n",
       "      <td>-0.014413</td>\n",
       "      <td>0.090550</td>\n",
       "      <td>-0.439741</td>\n",
       "      <td>0.938354</td>\n",
       "      <td>0.075221</td>\n",
       "      <td>-0.562872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analysis</th>\n",
       "      <td>-0.030814</td>\n",
       "      <td>0.155885</td>\n",
       "      <td>0.950019</td>\n",
       "      <td>0.416490</td>\n",
       "      <td>0.075221</td>\n",
       "      <td>-0.637100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anal</th>\n",
       "      <td>-0.041172</td>\n",
       "      <td>0.157398</td>\n",
       "      <td>0.976989</td>\n",
       "      <td>0.444969</td>\n",
       "      <td>0.079646</td>\n",
       "      <td>-0.824967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>research</th>\n",
       "      <td>-0.046988</td>\n",
       "      <td>0.151486</td>\n",
       "      <td>1.224107</td>\n",
       "      <td>1.067692</td>\n",
       "      <td>0.070796</td>\n",
       "      <td>-0.970337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market</th>\n",
       "      <td>-0.046988</td>\n",
       "      <td>0.151486</td>\n",
       "      <td>1.224107</td>\n",
       "      <td>1.067692</td>\n",
       "      <td>0.070796</td>\n",
       "      <td>-0.970337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             return       dev      skew       kurt  freq_occurance  \\\n",
       "first      0.073607  0.147450  0.456285  -1.116461        0.075221   \n",
       "positive   0.051755  0.134496  0.373000  -0.289800        0.115044   \n",
       "result     0.059078  0.178998  2.363357   8.521557        0.207965   \n",
       "line       0.052210  0.163599  0.225875  -0.954824        0.115044   \n",
       "announce   0.047411  0.156897  0.333173  -0.739548        0.203540   \n",
       "study      0.066944  0.227307  2.116217   5.379617        0.207965   \n",
       "treat      0.049928  0.208747  2.251961   6.192323        0.146018   \n",
       "clinical   0.051560  0.220976  2.059625   5.814816        0.238938   \n",
       "data       0.022746  0.120187  0.336363  -0.190480        0.115044   \n",
       "treatment  0.020971  0.139303  0.965044  -0.214014        0.123894   \n",
       "phase      0.024299  0.173815  1.880707   6.853316        0.685841   \n",
       "initiate   0.019955  0.143418  0.466266  -0.204099        0.097345   \n",
       "cancer     0.013988  0.120818  0.200386   0.171816        0.097345   \n",
       "patient    0.015926  0.190402  2.468305   8.815539        0.194690   \n",
       "trial      0.004705  0.137817  0.570613   0.136804        0.349558   \n",
       "report     0.005654  0.228321  3.358050  10.662194        0.079646   \n",
       "present   -0.002179  0.134554  0.514281   0.299960        0.128319   \n",
       "meet      -0.014413  0.090550 -0.439741   0.938354        0.075221   \n",
       "analysis  -0.030814  0.155885  0.950019   0.416490        0.075221   \n",
       "anal      -0.041172  0.157398  0.976989   0.444969        0.079646   \n",
       "research  -0.046988  0.151486  1.224107   1.067692        0.070796   \n",
       "market    -0.046988  0.151486  1.224107   1.067692        0.070796   \n",
       "\n",
       "           sharpe_ratio  \n",
       "first          1.414034  \n",
       "positive       1.071286  \n",
       "result         0.925543  \n",
       "line           0.888904  \n",
       "announce       0.836712  \n",
       "study          0.830850  \n",
       "treat          0.664431  \n",
       "clinical       0.649435  \n",
       "data           0.487325  \n",
       "treatment      0.382884  \n",
       "phase          0.363305  \n",
       "initiate       0.351025  \n",
       "cancer         0.271105  \n",
       "patient        0.202019  \n",
       "trial          0.039105  \n",
       "report         0.035851  \n",
       "present       -0.110766  \n",
       "meet          -0.562872  \n",
       "analysis      -0.637100  \n",
       "anal          -0.824967  \n",
       "research      -0.970337  \n",
       "market        -0.970337  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_return_details_per_word(article_df, return_df, holding_period, cut_off=0.05):\n",
    "    set_of_words = clean_word_list(article_df, cut_off)\n",
    "    \n",
    "    res_dict = {}\n",
    "    for word in set_of_words:\n",
    "        event_id_list = article_df.loc[article_df.title.str.contains(word)].index.tolist()\n",
    "        #print(event_id_list)\n",
    "        returns = return_df[\"R_{}\".format(holding_period - 1)].iloc[event_id_list].dropna()\n",
    "        res_dict[word] = [\n",
    "            np.mean(returns), \n",
    "            np.std(returns), \n",
    "            skew(returns.values), \n",
    "            kurtosis(returns.values),\n",
    "            returns.shape[0]/article_df.shape[0]\n",
    "        ]\n",
    "    \n",
    "    cols = [\"return\", \"dev\", \"skew\", \"kurt\", \"freq_occurance\"]\n",
    "    \n",
    "    return pd.DataFrame(res_dict, index=cols)\n",
    "\n",
    "def sharpe_ratio(row, holding_period, annual_risk_free_rate):\n",
    "    scale_param = 252 / holding_period # This will be used to annualize the expected return \n",
    "                                       # and the deviation\n",
    "    num = (scale_param * row[\"return\"] - annual_risk_free_rate) \n",
    "    den = (np.sqrt(scale_param) * row[\"dev\"])\n",
    "    return num / den\n",
    "\n",
    "holding_period = 30\n",
    "risk_free_rate = 0.025\n",
    "\n",
    "# In case the user inserts a holding period longer than allowed\n",
    "holding_period = min([len(return_window.columns), holding_period])\n",
    "\n",
    "res = get_return_details_per_word(articles, return_window, holding_period, 0.1).T    \n",
    "\n",
    "res[\"sharpe_ratio\"] = res.apply(sharpe_ratio, args=(holding_period, risk_free_rate), axis=1)\n",
    "\n",
    "res.sort_values(\"sharpe_ratio\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Alright, so I am not sure if I believe the results at the moment as they seem too good to be true for a first run.\n",
    "\n",
    "**Interesting Results**\n",
    "1. When filtered first for the word \"phase\" and then for the word \"first\" the Sharpe ratio turns out to be 1.4. This result seems to be very nice. The issue here is there is only a 7% occurrance out of the number of articles tagged with \"phase\". That equates to 17 instances. Is this statistically significant enough to trade?\n",
    "2. When filtered first for the word \"phase\" and then for the word \"positive\" the Sharpe ratio turns out to be 1.1. There is 11.5% occurance which is a bit better than the word \"first\" occuring 26 times. Again, the question is, is this statistically significant?\n",
    "\n",
    "**Short Comings**\n",
    "A few major shortcoming derive from this piece of research, mainly in data collection.\n",
    "\n",
    "1. The news articles are largely only from the last few years. There is clearly a survivor bias inherent in the data. \n",
    "2. Only a subset of the universe of bio-pharmaceutical stocks were used. Nothing outside of our Market Cap. range was used, so if a stock was successful, it would be out of bounds.\n",
    "3. If a stock had delisted, it would no longer be in the watchlist and so that data is not reflected here.\n",
    "\n",
    "**Next Steps**\n",
    "1. The main way to overcome this is to go to a data vendor to collect delisted stocks over the past n-years then to scrape those articles. Further, would like to include all of the watchlist instead of just our subsection of the market cap.\n",
    "\n",
    "2. Need to refactor this notebook into a unified code so it can be used on a larger scale once more data is collected.\n",
    "\n",
    "3. Another thing that would be interested is to create a backtest that can help to look at how accurate the research is. Having 2 numbers to look at and correlate the statistics would help ensure that the functionality is working correctly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
