{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking through N-Grams as Factors\n",
    "### (Started July 2, 2019)\n",
    "\n",
    "## Introduction\n",
    "After seeing the potentially strong results from filtering the articles by \"phase\" then by a second keyword, it became clear that there could be some other interesting groupings of words.\n",
    "\n",
    "The intuition is that there are likely to be certain groups of words that could result in statistically significant risk-adjusted returns.\n",
    "\n",
    "The high-level approach will be:\n",
    "1. Reduce the words in the corpus of text as much as possible. The key here is to remove as many irrelevant words.\n",
    "2. For each set of n-grams:\n",
    "    * Filter the article Data Frame using the words in the n-gram\n",
    "    * Get the Return metrics for the filtered articles\n",
    "3. Calculate and sort by the metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents \n",
    "\n",
    "1. [\"Imports, Settings and Data Loading\"](#1)\n",
    "2. [\"Text Cleaning and Feature Reduction\"](#2)\n",
    "3. [\"Build N-Gram Functionality](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## Imports, Settings and Data Loading\n",
    "\n",
    "Note: All of this section came from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Standard Libraries\n",
    "from itertools import combinations\n",
    "\n",
    "# Numerical Libraries\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Visual Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Local Package Libraries\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from src.data.make_dataset import *\n",
    "from src.features.general_helper_functions import *\n",
    "from src.features.text_cleaning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Settings\n",
    "\n",
    "# Stop the warnings for chain in pandas...\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important;}</style>\"))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, watchlist_raw, stock_prices_raw = get_raw_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(Added the cleaning and formatting functions to make_dataset.py - July 2, 2019)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ACAD    ACHC  ACOR  ADUS  AERI  AGIO  AIMT  AKCA  AKRX  ALDR  \\\n",
      "1998-01-02   NaN  3.5958   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "1998-01-05   NaN  3.4911   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "1998-01-06   NaN  3.5958   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "1998-01-07   NaN  3.5958   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "1998-01-08   NaN  3.5958   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "            ...   VRAY  VREX  WMGI  WVE  XENT  XLRN  XNCR  XON  YI  ZGNX  \n",
      "1998-01-02  ...    NaN   NaN   NaN  NaN   NaN   NaN   NaN  NaN NaN   NaN  \n",
      "1998-01-05  ...    NaN   NaN   NaN  NaN   NaN   NaN   NaN  NaN NaN   NaN  \n",
      "1998-01-06  ...    NaN   NaN   NaN  NaN   NaN   NaN   NaN  NaN NaN   NaN  \n",
      "1998-01-07  ...    NaN   NaN   NaN  NaN   NaN   NaN   NaN  NaN NaN   NaN  \n",
      "1998-01-08  ...    NaN   NaN   NaN  NaN   NaN   NaN   NaN  NaN NaN   NaN  \n",
      "\n",
      "[5 rows x 197 columns]\n",
      "        time                                              title ticker  \\\n",
      "0 2019-06-04  acadia pharmaceuticals to present at the goldm...   ACAD   \n",
      "1 2019-05-18  acadia pharmaceuticals to present phase 2 clar...   ACAD   \n",
      "2 2019-05-15  fastest growing companies/startups in san fran...   ACAD   \n",
      "3 2019-05-07  acadia pharmaceuticals to present at the bank ...   ACAD   \n",
      "4 2019-05-02  alzheimer's disease: pipeline review, develope...   ACAD   \n",
      "\n",
      "                                             article  \n",
      "0   san diego--(business wire)--acadia pharmaceut...  \n",
      "1   san diego--(business wire)--acadia pharmaceut...  \n",
      "2   boulder, colo.--(business wire)--growjo annou...  \n",
      "3   san diego--(business wire)--acadia pharmaceut...  \n",
      "4   dublin--(business wire)--the \"alzheimer's dis...  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_0</th>\n",
       "      <th>R_1</th>\n",
       "      <th>R_2</th>\n",
       "      <th>R_3</th>\n",
       "      <th>R_4</th>\n",
       "      <th>R_5</th>\n",
       "      <th>R_6</th>\n",
       "      <th>R_7</th>\n",
       "      <th>R_8</th>\n",
       "      <th>R_9</th>\n",
       "      <th>...</th>\n",
       "      <th>R_19</th>\n",
       "      <th>R_20</th>\n",
       "      <th>R_21</th>\n",
       "      <th>R_22</th>\n",
       "      <th>R_23</th>\n",
       "      <th>R_24</th>\n",
       "      <th>R_25</th>\n",
       "      <th>R_26</th>\n",
       "      <th>R_27</th>\n",
       "      <th>R_28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016568</td>\n",
       "      <td>-0.017357</td>\n",
       "      <td>0.019329</td>\n",
       "      <td>0.012229</td>\n",
       "      <td>0.010651</td>\n",
       "      <td>0.008679</td>\n",
       "      <td>0.011045</td>\n",
       "      <td>-0.042998</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.022880</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.010794</td>\n",
       "      <td>-0.035081</td>\n",
       "      <td>-0.065921</td>\n",
       "      <td>-0.015420</td>\n",
       "      <td>-0.030840</td>\n",
       "      <td>-0.023130</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.007710</td>\n",
       "      <td>-0.052043</td>\n",
       "      <td>-0.040093</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011951</td>\n",
       "      <td>-0.064765</td>\n",
       "      <td>-0.020046</td>\n",
       "      <td>-0.000386</td>\n",
       "      <td>0.026214</td>\n",
       "      <td>-0.008096</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013173</td>\n",
       "      <td>0.006587</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>-0.045719</td>\n",
       "      <td>-0.008136</td>\n",
       "      <td>0.005037</td>\n",
       "      <td>-0.005812</td>\n",
       "      <td>-0.030221</td>\n",
       "      <td>-0.061217</td>\n",
       "      <td>-0.010461</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001550</td>\n",
       "      <td>-0.034870</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>-0.005812</td>\n",
       "      <td>-0.007361</td>\n",
       "      <td>-0.009299</td>\n",
       "      <td>-0.006974</td>\n",
       "      <td>-0.060054</td>\n",
       "      <td>-0.015110</td>\n",
       "      <td>0.004649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.050588</td>\n",
       "      <td>0.012157</td>\n",
       "      <td>0.025490</td>\n",
       "      <td>0.018824</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>-0.034118</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.017255</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059216</td>\n",
       "      <td>-0.043529</td>\n",
       "      <td>-0.005882</td>\n",
       "      <td>0.010588</td>\n",
       "      <td>-0.023137</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>0.004706</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.005098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        R_0       R_1       R_2       R_3       R_4       R_5       R_6  \\\n",
       "0  0.016568 -0.017357  0.019329  0.012229  0.010651  0.008679  0.011045   \n",
       "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2 -0.010794 -0.035081 -0.065921 -0.015420 -0.030840 -0.023130  0.000771   \n",
       "3  0.013173  0.006587  0.001162 -0.045719 -0.008136  0.005037 -0.005812   \n",
       "4  0.040000  0.050588  0.012157  0.025490  0.018824  0.013333 -0.034118   \n",
       "\n",
       "        R_7       R_8       R_9    ...         R_19      R_20      R_21  \\\n",
       "0 -0.042998  0.002761  0.022880    ...          NaN       NaN       NaN   \n",
       "1       NaN       NaN       NaN    ...          NaN       NaN       NaN   \n",
       "2  0.007710 -0.052043 -0.040093    ...    -0.011951 -0.064765 -0.020046   \n",
       "3 -0.030221 -0.061217 -0.010461    ...    -0.001550 -0.034870  0.001162   \n",
       "4  0.003922  0.017255  0.006275    ...    -0.059216 -0.043529 -0.005882   \n",
       "\n",
       "       R_22      R_23      R_24      R_25      R_26      R_27      R_28  \n",
       "0       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "1       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "2 -0.000386  0.026214 -0.008096  0.002313       NaN       NaN       NaN  \n",
       "3 -0.005812 -0.007361 -0.009299 -0.006974 -0.060054 -0.015110  0.004649  \n",
       "4  0.010588 -0.023137  0.013333  0.006275  0.004706  0.002745  0.005098  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df = clean_and_open_business_wire_data_01(None)\n",
    "article_df.time = pd.to_datetime(article_df.time)\n",
    "\n",
    "# Watchlist\n",
    "watchlist_df = clean_and_format_watchlist(watchlist_raw, article_df.ticker.unique())\n",
    "\n",
    "\n",
    "# Stock Prices\n",
    "prices_df = clean_and_format_prices(stock_prices_raw, article_df.ticker.unique())\n",
    "\n",
    "# Return Window\n",
    "return_window = compute_return_window(article_df, prices_df, n_window=30)\n",
    "\n",
    "return_window.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning and Feature Reduction\n",
    "\n",
    "Note: The first block is also from the previous Notebook. Should probably add these to src.\n",
    "\n",
    "*(Added to src: nlp_functions.py - July 2, 2019)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_frequency(word_list, df):\n",
    "    d = {word: sum([1 if word in article else 0 for article in df.title.values])/df.shape[0] for word in word_list}\n",
    "    \n",
    "    return pd.Series(d, index = d.keys()).sort_values(ascending=False)\n",
    "\n",
    "def get_list_of_words(articles, cut_off):    \n",
    "    combined_titles = \" \".join(articles.title.values.tolist())\n",
    "\n",
    "    set_of_words = list(set(combined_titles.split(\" \")))\n",
    "    \n",
    "    set_of_words = [word for word in set_of_words if len(word) > 3]\n",
    "\n",
    "    word_frequency = calculate_word_frequency(set_of_words, articles)\n",
    "    set_of_words = word_frequency.loc[word_frequency > cut_off].index\n",
    "    return set_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n"
     ]
    }
   ],
   "source": [
    "article_df = clean_text(article_df, \"title\")\n",
    "\n",
    "list_of_words = get_list_of_words(article_df, cut_off=0.01)\n",
    "\n",
    "print(len(list_of_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now can go through the article titles and filter out all words that are not in the list_of_words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_sublist_words(text, list_of_words):\n",
    "    return \" \".join([word for word in text.split(\" \") if word in list_of_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df.title = article_df.title.apply(keep_sublist_words, args=(list_of_words,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can drop the columns \"ticker\" and \"article\" as they won't be needed. \n",
    "\n",
    "Further, it will be useful to have a column for each word with a value of True or False if the word exists in the title or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df = article_df.drop([\"ticker\", \"article\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8433, 256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in list_of_words:\n",
    "    article_df[word] = article_df.title.str.contains(word)\n",
    "    \n",
    "article_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>mark</th>\n",
       "      <th>market</th>\n",
       "      <th>search</th>\n",
       "      <th>research</th>\n",
       "      <th>chan</th>\n",
       "      <th>hand</th>\n",
       "      <th>researchandmarkets</th>\n",
       "      <th>global</th>\n",
       "      <th>...</th>\n",
       "      <th>american</th>\n",
       "      <th>stage</th>\n",
       "      <th>unite</th>\n",
       "      <th>micro</th>\n",
       "      <th>strategy</th>\n",
       "      <th>cure</th>\n",
       "      <th>administration</th>\n",
       "      <th>light</th>\n",
       "      <th>receive</th>\n",
       "      <th>next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>pharmaceutical present annual global healthcar...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-18</td>\n",
       "      <td>pharmaceutical present phase result treatment ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-15</td>\n",
       "      <td>grow company award</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>pharmaceutical present america health care con...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>disease pipeline review insight researchandmar...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time                                              title   mark  \\\n",
       "0 2019-06-04  pharmaceutical present annual global healthcar...  False   \n",
       "1 2019-05-18  pharmaceutical present phase result treatment ...  False   \n",
       "2 2019-05-15                                 grow company award  False   \n",
       "3 2019-05-07  pharmaceutical present america health care con...  False   \n",
       "4 2019-05-02  disease pipeline review insight researchandmar...   True   \n",
       "\n",
       "   market  search  research   chan   hand  researchandmarkets  global  ...    \\\n",
       "0   False   False     False  False  False               False    True  ...     \n",
       "1   False   False     False  False  False               False   False  ...     \n",
       "2   False   False     False  False  False               False   False  ...     \n",
       "3   False   False     False  False  False               False   False  ...     \n",
       "4    True    True      True   True   True                True   False  ...     \n",
       "\n",
       "   american  stage  unite  micro  strategy   cure  administration  light  \\\n",
       "0     False  False  False  False     False  False           False  False   \n",
       "1      True  False  False  False     False  False           False  False   \n",
       "2     False  False  False  False     False  False           False  False   \n",
       "3     False  False  False  False     False  False           False  False   \n",
       "4     False  False  False  False     False  False           False  False   \n",
       "\n",
       "   receive   next  \n",
       "0    False  False  \n",
       "1    False  False  \n",
       "2    False  False  \n",
       "3    False  False  \n",
       "4    False  False  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "\n",
    "## Build N-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_gram(words, n):\n",
    "    return combinations(words, n)\n",
    "\n",
    "def get_ngram_articles(articles, ngram_tuple):\n",
    "    temp_articles = articles.copy()\n",
    "    for word in ngram_tuple:\n",
    "        temp_articles = temp_articles.loc[temp_articles[word]]\n",
    "    return temp_articles.index.tolist()\n",
    "\n",
    "def get_dict_ngram_articles(articles, list_of_words):\n",
    "    ngram = get_n_gram(list_of_words, 2)\n",
    "    return {word_tuple: get_ngram_articles(article_df, word_tuple) for word_tuple in ngram}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32131\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dict_linking_ngram_to_indexes = get_dict_ngram_articles(article_df, list_of_words)\n",
    "\n",
    "\n",
    "print(len(dict_linking_ngram_to_indexes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "\n",
    "## Iterate and Calculate Metrics per N-Gram\n",
    "\n",
    "For each n-gram will need to collect the stock returns for our window, then calculate the return metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original function is from Notebook 02 and converted to work with n-grams\n",
    "\n",
    "def get_return_details_per_word(article_df, return_df, word_list, holding_period, cut_off=0.05):\n",
    "    set_of_ngrams = get_n_gram(word_list, 2)\n",
    "    \n",
    "    res_dict = {}\n",
    "    for ngram in set_of_ngrams:\n",
    "        event_id_list = get_ngram_articles(article_df, ngram)\n",
    "        #print(event_id_list)\n",
    "        returns = return_df[\"R_{}\".format(holding_period - 1)].iloc[event_id_list].dropna()\n",
    "        res_dict[ngram] = [\n",
    "            np.mean(returns), \n",
    "            np.std(returns), \n",
    "            skew(returns.values), \n",
    "            kurtosis(returns.values),\n",
    "            returns.shape[0]/article_df.shape[0]\n",
    "        ]\n",
    "    \n",
    "    cols = [\"return\", \"dev\", \"skew\", \"kurt\", \"freq_occurance\"]\n",
    "    \n",
    "    return pd.DataFrame(res_dict, index=cols).T\n",
    "\n",
    "def sharpe_ratio(row, holding_period, annual_risk_free_rate):\n",
    "    scale_param = 252 / holding_period # This will be used to annualize the expected return \n",
    "                                       # and the deviation\n",
    "    num = (scale_param * row[\"return\"] - annual_risk_free_rate) \n",
    "    den = (np.sqrt(scale_param) * row[\"dev\"])\n",
    "    return num / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = get_return_details_per_word(article_df, \n",
    "                                     return_window, \n",
    "                                     list_of_words, \n",
    "                                     holding_period=20, \n",
    "                                     cut_off=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">mark</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">cure</th>\n",
       "      <th colspan=\"3\" halign=\"left\">administration</th>\n",
       "      <th colspan=\"2\" halign=\"left\">light</th>\n",
       "      <th>receive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>market</th>\n",
       "      <th>search</th>\n",
       "      <th>research</th>\n",
       "      <th>chan</th>\n",
       "      <th>hand</th>\n",
       "      <th>researchandmarkets</th>\n",
       "      <th>global</th>\n",
       "      <th>line</th>\n",
       "      <th>port</th>\n",
       "      <th>pipeline</th>\n",
       "      <th>...</th>\n",
       "      <th>administration</th>\n",
       "      <th>light</th>\n",
       "      <th>receive</th>\n",
       "      <th>next</th>\n",
       "      <th>light</th>\n",
       "      <th>receive</th>\n",
       "      <th>next</th>\n",
       "      <th>receive</th>\n",
       "      <th>next</th>\n",
       "      <th>next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>return</th>\n",
       "      <td>0.106122</td>\n",
       "      <td>0.105561</td>\n",
       "      <td>0.105561</td>\n",
       "      <td>0.075810</td>\n",
       "      <td>0.075810</td>\n",
       "      <td>0.075810</td>\n",
       "      <td>0.109309</td>\n",
       "      <td>0.113945</td>\n",
       "      <td>0.110854</td>\n",
       "      <td>0.113865</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.530292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.525436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev</th>\n",
       "      <td>0.223200</td>\n",
       "      <td>0.222447</td>\n",
       "      <td>0.222447</td>\n",
       "      <td>0.200197</td>\n",
       "      <td>0.200197</td>\n",
       "      <td>0.200197</td>\n",
       "      <td>0.226605</td>\n",
       "      <td>0.226717</td>\n",
       "      <td>0.221694</td>\n",
       "      <td>0.226786</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skew</th>\n",
       "      <td>0.735344</td>\n",
       "      <td>0.740837</td>\n",
       "      <td>0.740837</td>\n",
       "      <td>1.005750</td>\n",
       "      <td>1.005750</td>\n",
       "      <td>1.005750</td>\n",
       "      <td>0.703906</td>\n",
       "      <td>0.673792</td>\n",
       "      <td>0.678931</td>\n",
       "      <td>0.674687</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kurt</th>\n",
       "      <td>-0.769131</td>\n",
       "      <td>-0.755797</td>\n",
       "      <td>-0.755797</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>-0.845560</td>\n",
       "      <td>-0.914813</td>\n",
       "      <td>-0.854988</td>\n",
       "      <td>-0.913864</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq_occurance</th>\n",
       "      <td>0.426894</td>\n",
       "      <td>0.411004</td>\n",
       "      <td>0.411004</td>\n",
       "      <td>0.263607</td>\n",
       "      <td>0.263607</td>\n",
       "      <td>0.263607</td>\n",
       "      <td>0.212380</td>\n",
       "      <td>0.149413</td>\n",
       "      <td>0.104115</td>\n",
       "      <td>0.149176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mark                                          \\\n",
       "                  market    search  research      chan      hand   \n",
       "return          0.106122  0.105561  0.105561  0.075810  0.075810   \n",
       "dev             0.223200  0.222447  0.222447  0.200197  0.200197   \n",
       "skew            0.735344  0.740837  0.740837  1.005750  1.005750   \n",
       "kurt           -0.769131 -0.755797 -0.755797  0.001682  0.001682   \n",
       "freq_occurance  0.426894  0.411004  0.411004  0.263607  0.263607   \n",
       "\n",
       "                                                                           \\\n",
       "               researchandmarkets    global      line      port  pipeline   \n",
       "return                   0.075810  0.109309  0.113945  0.110854  0.113865   \n",
       "dev                      0.200197  0.226605  0.226717  0.221694  0.226786   \n",
       "skew                     1.005750  0.703906  0.673792  0.678931  0.674687   \n",
       "kurt                     0.001682 -0.845560 -0.914813 -0.854988 -0.913864   \n",
       "freq_occurance           0.263607  0.212380  0.149413  0.104115  0.149176   \n",
       "\n",
       "                  ...              cure                    administration  \\\n",
       "                  ...    administration light receive next          light   \n",
       "return            ...               NaN   NaN     NaN  NaN            NaN   \n",
       "dev               ...               NaN   NaN     NaN  NaN            NaN   \n",
       "skew              ...               NaN   NaN     NaN  NaN            NaN   \n",
       "kurt              ...               NaN   NaN     NaN  NaN            NaN   \n",
       "freq_occurance    ...               0.0   0.0     0.0  0.0            0.0   \n",
       "\n",
       "                                light        receive  \n",
       "                 receive next receive next      next  \n",
       "return          0.530292  NaN     NaN  NaN  0.525436  \n",
       "dev             0.000000  NaN     NaN  NaN  0.000000  \n",
       "skew            0.000000  NaN     NaN  NaN  0.000000  \n",
       "kurt           -3.000000  NaN     NaN  NaN -3.000000  \n",
       "freq_occurance  0.000119  0.0     0.0  0.0  0.000119  \n",
       "\n",
       "[5 rows x 32131 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
