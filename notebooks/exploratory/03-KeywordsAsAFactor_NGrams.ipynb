{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking through N-Grams as Factors\n",
    "### (Started July 2, 2019)\n",
    "\n",
    "## Introduction\n",
    "After seeing the potentially strong results from filtering the articles by \"phase\" then by a second keyword, it became clear that there could be some other interesting groupings of words.\n",
    "\n",
    "The intuition is that there are likely to be certain groups of words that could result in statistically significant risk-adjusted returns.\n",
    "\n",
    "The high-level approach will be:\n",
    "1. Reduce the words in the corpus of text as much as possible. The key here is to remove as many irrelevant words.\n",
    "2. For each set of n-grams:\n",
    "    * Filter the article Data Frame using the words in the n-gram\n",
    "    * Get the Return metrics for the filtered articles\n",
    "3. Calculate and sort by the metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents \n",
    "\n",
    "1. [\"Imports, Settings and Data Loading\"](#1)\n",
    "2. [\"Text Cleaning and Feature Reduction\"](#2)\n",
    "3. [\"Build N-Gram Functionality](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## Imports, Settings and Data Loading\n",
    "\n",
    "Note: All of this section came from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# Standard Libraries\n",
    "from itertools import combinations\n",
    "\n",
    "# Numerical Libraries\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Visual Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Local Package Libraries\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from src.data.make_dataset import *\n",
    "from src.features.general_helper_functions import GetPrices\n",
    "from src.features.text_cleaning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Settings\n",
    "\n",
    "# Stop the warnings for chain in pandas...\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important;}</style>\"))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, watchlist_raw, stock_prices_raw = get_raw_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(Added the cleaning and formatting functions to make_dataset.py - July 2, 2019)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((197, 4), (5402, 197))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df = clean_and_open_business_wire_data_01(None)\n",
    "article_df.time = pd.to_datetime(article_df.time)\n",
    "\n",
    "# Watchlist\n",
    "watchlist_df = clean_and_format_watchlist(watchlist_raw, article_df.ticker.unique())\n",
    "\n",
    "\n",
    "# Stock Prices\n",
    "prices_df = clean_and_format_prices(stock_prices_raw, article_df.ticker.unique())\n",
    "\n",
    "watchlist_df.shape, prices_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning and Feature Reduction\n",
    "\n",
    "Note: The first block is also from the previous Notebook. Should probably add these to src.\n",
    "\n",
    "*(Added to src: nlp_functions.py - July 2, 2019)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df, column_name):\n",
    "    df[column_name] = df[column_name].apply(remove_white_spaces)\n",
    "    df[column_name] = df[column_name].apply(remove_non_alphanumeric)\n",
    "    df[column_name] = df[column_name].apply(remove_numbers)\n",
    "    df[column_name] = df[column_name].apply(remove_stop_words)\n",
    "    df[column_name] = df[column_name].apply(lemmatize_text)\n",
    "    return df\n",
    "\n",
    "def calculate_word_frequency(word_list, df):\n",
    "    d = {word: sum([1 if word in article else 0 for article in df.title.values])/df.shape[0] for word in word_list}\n",
    "    \n",
    "    return pd.Series(d, index = d.keys()).sort_values(ascending=False)\n",
    "\n",
    "def get_list_of_words(articles, cut_off):    \n",
    "    combined_titles = \" \".join(articles.title.values.tolist())\n",
    "\n",
    "    set_of_words = list(set(combined_titles.split(\" \")))\n",
    "    \n",
    "    set_of_words = [word for word in set_of_words if len(word) > 3]\n",
    "\n",
    "    word_frequency = calculate_word_frequency(set_of_words, articles)\n",
    "    set_of_words = word_frequency.loc[word_frequency > cut_off].index\n",
    "    return set_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n"
     ]
    }
   ],
   "source": [
    "article_df = clean_text(article_df, \"title\")\n",
    "\n",
    "list_of_words = get_list_of_words(article_df, cut_off=0.01)\n",
    "\n",
    "print(len(list_of_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now can go through the article titles and filter out all words that are not in the list_of_words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_sublist_words(text, list_of_words):\n",
    "    return \" \".join([word for word in text.split(\" \") if word in list_of_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df.title = article_df.title.apply(keep_sublist_words, args=(list_of_words,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can drop the columns \"ticker\" and \"article\" as they won't be needed. \n",
    "\n",
    "Further, it will be useful to have a column for each word with a value of True or False if the word exists in the title or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df = article_df.drop([\"ticker\", \"article\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8433, 256)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in list_of_words:\n",
    "    article_df[word] = article_df.title.str.contains(word)\n",
    "    \n",
    "article_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>mark</th>\n",
       "      <th>market</th>\n",
       "      <th>search</th>\n",
       "      <th>research</th>\n",
       "      <th>chan</th>\n",
       "      <th>hand</th>\n",
       "      <th>researchandmarkets</th>\n",
       "      <th>global</th>\n",
       "      <th>...</th>\n",
       "      <th>micro</th>\n",
       "      <th>american</th>\n",
       "      <th>unite</th>\n",
       "      <th>stage</th>\n",
       "      <th>cure</th>\n",
       "      <th>strategy</th>\n",
       "      <th>light</th>\n",
       "      <th>next</th>\n",
       "      <th>receive</th>\n",
       "      <th>administration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>pharmaceutical present annual global healthcar...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-18</td>\n",
       "      <td>pharmaceutical present phase result treatment ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-15</td>\n",
       "      <td>grow company award</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>pharmaceutical present america health care con...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>disease pipeline review insight researchandmar...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time                                              title   mark  \\\n",
       "0 2019-06-04  pharmaceutical present annual global healthcar...  False   \n",
       "1 2019-05-18  pharmaceutical present phase result treatment ...  False   \n",
       "2 2019-05-15                                 grow company award  False   \n",
       "3 2019-05-07  pharmaceutical present america health care con...  False   \n",
       "4 2019-05-02  disease pipeline review insight researchandmar...   True   \n",
       "\n",
       "   market  search  research   chan   hand  researchandmarkets  global  \\\n",
       "0   False   False     False  False  False               False    True   \n",
       "1   False   False     False  False  False               False   False   \n",
       "2   False   False     False  False  False               False   False   \n",
       "3   False   False     False  False  False               False   False   \n",
       "4    True    True      True   True   True                True   False   \n",
       "\n",
       "        ...        micro  american  unite  stage   cure  strategy  light  \\\n",
       "0       ...        False     False  False  False  False     False  False   \n",
       "1       ...        False      True  False  False  False     False  False   \n",
       "2       ...        False     False  False  False  False     False  False   \n",
       "3       ...        False     False  False  False  False     False  False   \n",
       "4       ...        False     False  False  False  False     False  False   \n",
       "\n",
       "    next  receive  administration  \n",
       "0  False    False           False  \n",
       "1  False    False           False  \n",
       "2  False    False           False  \n",
       "3  False    False           False  \n",
       "4  False    False           False  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "\n",
    "## Build N-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram(words, n):\n",
    "    return combinations(words, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_set_of_articles_for_ngram(articles, ngram_tuple):\n",
    "    temp_articles = articles.copy()\n",
    "    for word in ngram_tuple:\n",
    "        temp_articles = temp_articles.loc[temp_articles[word]]\n",
    "    return temp_articles.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ngram = n_gram(list_of_words, 2)\n",
    "\n",
    "dict_linking_ngram_to_indexes = {word_tuple: find_set_of_articles_for_ngram(article_df, item) for word_tuple in ngram}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this is a very large number of pairs. Is it necessary to check them all? How could we further reduce the number of words? Perhaps can go back to the idea of frequency to remove all pairs of words with a low frequency!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32131"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_linking_ngram_to_indexes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
